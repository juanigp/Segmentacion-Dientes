{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2 molares.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SnoopiACK/DientesMask/blob/master/demo_deteccion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII",
        "colab_type": "text"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies: (use cu100 because colab is on CUDA 10.0)\n",
        "!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "torch.__version__\n",
        "!gcc --version\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import torch, torchvision\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo",
        "colab_type": "text"
      },
      "source": [
        "# Train on a custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "6bec37e3-a86d-4237-84f7-8e905f78001a"
      },
      "source": [
        "import os\n",
        "repo_url = 'https://github.com/SnoopiACK/DientesMask'\n",
        "!git clone {repo_url}\n",
        "#%cd /content\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DientesMask'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 701 (delta 44), reused 79 (delta 14), pack-reused 557\u001b[K\n",
            "Receiving objects: 100% (701/701), 299.22 MiB | 35.59 MiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n",
            "Checking out files: 100% (444/444), done.\n",
            "/content/DientesMask\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIbAM2pv-urF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import json\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "\n",
        "#dado el numero de diente, saber si es incisivo, canino, premolar, molar\n",
        "def get_tooth_type(tooth_number):\n",
        "  if len(tooth_number) == 2:\n",
        "    c = tooth_number[1]\n",
        "  else:\n",
        "    c = tooth_number \n",
        "  if (c == '1') or (c == '2'):\n",
        "    tooth_type = 'Incisivo'\n",
        "  elif (c == '3'):\n",
        "    tooth_type = 'Canino'\n",
        "  elif (c == '4') or (c == '5'):\n",
        "    tooth_type = 'Premolar'\n",
        "  else:\n",
        "    tooth_type = 'Molar'  \n",
        "  return tooth_type\n",
        "  \n",
        "#encoding de tipo de diente\n",
        "def tooth_type_encoder(tooth_type):\n",
        "  encoder_dict = {\n",
        "      \"Incisivo\":0,\n",
        "      \"Canino\":1,\n",
        "      \"Premolar\":2,\n",
        "      \"Molar\":3\n",
        "  }\n",
        "  return encoder_dict[tooth_type]\n",
        "\n",
        "#function that makes the data dictionaries for detectron to use\n",
        "#jsons_path: folder full of .json files\n",
        "#images_path: folder where the dataset images are\n",
        "def make_data_dicts(jsons_path, images_path):\n",
        "    dataset_dicts = []\n",
        "    files = glob.glob(jsons_path + \"/*\")\n",
        "    jsons = [file for file in files if '.json' in file]\n",
        "    #images = [file for file in files if not '.json' in file]\n",
        "    for json_filename in jsons:\n",
        "      json_file = json.load( open(json_filename, encoding = 'cp1252' ) )\n",
        "      record = {}\n",
        "      record[\"file_name\"] = images_path + '/' + json_file['imagePath']\n",
        "      record[\"image_id\"] = json_file['imagePath']\n",
        "      record[\"height\"] = json_file['imageHeight']\n",
        "      record[\"width\"] = json_file['imageWidth']\n",
        "      objs = []\n",
        "      for shape in json_file['shapes']:\n",
        "        shape_category = tooth_type_encoder( get_tooth_type(shape['label']) )\n",
        "        obj = {\n",
        "          \"bbox\": [round(shape['points'][0][0]), round(shape['points'][0][1]), round(shape['points'][1][0]), round(shape['points'][1][1])],\n",
        "          \"bbox_mode\": BoxMode.XYXY_ABS,  \n",
        "          \"category_id\": shape_category,\n",
        "        }\n",
        "        objs.append(obj)\n",
        "      record[\"annotations\"] = objs\n",
        "      dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "for d in [\"train\", \"test\"]:\n",
        "    DatasetCatalog.register(\"data_\" + d, lambda d=d: make_data_dicts(\"data/jsons_comparacion_de_redes/jsons_dientes_enumerados/\" + d, \"data/images\"))\n",
        "    MetadataCatalog.get(\"data_\" + d).set(thing_classes=[\"I\",\"C\",\"P\",\"M\"])\n",
        "dataset_metadata = MetadataCatalog.get(\"data_train\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E",
        "colab_type": "text"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkNbUzUOLYf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dicts = make_data_dicts(\"data/jsons_comparacion_de_redes/jsons_dientes_enumerados/train\", \"data/images\")\n",
        "for d in random.sample(dataset_dicts, 2):\n",
        "    print(d)\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=dataset_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy8aE-THxJIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.engine import DefaultTrainer\n",
        "class CustomTrainer(DefaultTrainer):\n",
        "\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"custom_eval\", exist_ok=True)\n",
        "        output_folder = \"custom_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FiT70iNUWcWN"
      },
      "source": [
        "## Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b33aaa9c-82fb-4e2c-8433-e3d7f104e6b2"
      },
      "source": [
        "%rm -rf output\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = ('data_train',)\n",
        "cfg.DATASETS.TEST = ('data_test',)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 1000  #  iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # number of classes\n",
        "cfg.TEST.EVAL_PERIOD = 10\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = CustomTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[05/23 16:21:26 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[05/23 16:21:27 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 55 images left.\n",
            "\u001b[32m[05/23 16:21:27 d2.data.common]: \u001b[0mSerializing 55 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:21:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
            "\u001b[32m[05/23 16:21:27 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/23 16:21:27 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[05/23 16:21:27 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/23 16:21:45 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:21:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:21:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:21:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.350420 (0.350420 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:21:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.301062 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:21:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:21:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:21:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
            "\u001b[32m[05/23 16:21:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.004 | 0.015  | 0.000  | 0.000 | 0.046 | 0.003 |\n",
            "\u001b[32m[05/23 16:21:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.000 | C          | 0.000 | P          | 0.011 |\n",
            "| M          | 0.005 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:21:48 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:21:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:21:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:21:48 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0040,0.0151,0.0000,0.0000,0.0460,0.0026\n",
            "\u001b[32m[05/23 16:22:05 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:22:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:22:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:22:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.346420 (0.346420 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:22:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.297573 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:22:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:22:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:22:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\n",
            "\u001b[32m[05/23 16:22:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.090 | 0.388  | 0.000  | 0.000 | 0.378 | 0.136 |\n",
            "\u001b[32m[05/23 16:22:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.000 | C          | 0.157 | P          | 0.202 |\n",
            "| M          | 0.000 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:22:08 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:22:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:22:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:22:08 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0896,0.3883,0.0000,0.0000,0.3782,0.1358\n",
            "\u001b[32m[05/23 16:22:08 d2.utils.events]: \u001b[0m eta: 0:29:01  iter: 19  total_loss: 6.589  loss_cls: 1.695  loss_box_reg: 0.355  loss_rpn_cls: 4.307  loss_rpn_loc: 0.271  time: 1.7470  data_time: 0.0349  lr: 0.000005  max_mem: 5647M\n",
            "\u001b[32m[05/23 16:22:25 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:22:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:22:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:22:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.346065 (0.346065 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:22:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.297182 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:22:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:22:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:22:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\n",
            "\u001b[32m[05/23 16:22:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.129 | 0.641  | 0.023  | 0.000 | 0.135 | 0.188 |\n",
            "\u001b[32m[05/23 16:22:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.000 | C          | 0.207 | P          | 0.309 |\n",
            "| M          | 0.000 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:22:28 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:22:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:22:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:22:28 d2.evaluation.testing]: \u001b[0mcopypaste: 0.1290,0.6410,0.0226,0.0000,0.1345,0.1879\n",
            "\u001b[32m[05/23 16:22:45 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:22:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:22:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:22:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.352250 (0.352250 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:22:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.302350 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:22:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:22:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:22:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.049\n",
            "\u001b[32m[05/23 16:22:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.192 | 0.816  | 0.028  | 0.000 | 0.449 | 0.222 |\n",
            "\u001b[32m[05/23 16:22:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.000 | C          | 0.189 | P          | 0.579 |\n",
            "| M          | 0.000 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:22:48 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:22:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:22:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:22:48 d2.evaluation.testing]: \u001b[0mcopypaste: 0.1921,0.8159,0.0280,0.0000,0.4493,0.2215\n",
            "\u001b[32m[05/23 16:22:48 d2.utils.events]: \u001b[0m eta: 0:28:27  iter: 39  total_loss: 2.808  loss_cls: 1.626  loss_box_reg: 0.789  loss_rpn_cls: 0.178  loss_rpn_loc: 0.196  time: 1.7411  data_time: 0.0052  lr: 0.000010  max_mem: 5647M\n",
            "\u001b[32m[05/23 16:23:06 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:23:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:23:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:23:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.349731 (0.349731 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:23:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.301623 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:23:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:23:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:23:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052\n",
            "\u001b[32m[05/23 16:23:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.223 | 0.899  | 0.023  | 0.000 | 0.620 | 0.238 |\n",
            "\u001b[32m[05/23 16:23:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.000 | C          | 0.145 | P          | 0.745 |\n",
            "| M          | 0.000 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:23:08 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:23:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:23:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:23:08 d2.evaluation.testing]: \u001b[0mcopypaste: 0.2226,0.8993,0.0225,0.0000,0.6196,0.2378\n",
            "\u001b[32m[05/23 16:23:26 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:23:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:23:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:23:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.360308 (0.360308 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:23:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.310315 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:23:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:23:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:23:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.059\n",
            "\u001b[32m[05/23 16:23:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.348 | 1.563  | 0.011  | 0.000 | 0.625 | 0.399 |\n",
            "\u001b[32m[05/23 16:23:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.000 | C          | 0.076 | P          | 1.314 |\n",
            "| M          | 0.000 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:23:29 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:23:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:23:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:23:29 d2.evaluation.testing]: \u001b[0mcopypaste: 0.3476,1.5628,0.0112,0.0000,0.6253,0.3995\n",
            "\u001b[32m[05/23 16:23:29 d2.utils.events]: \u001b[0m eta: 0:27:54  iter: 59  total_loss: 2.590  loss_cls: 1.499  loss_box_reg: 0.831  loss_rpn_cls: 0.060  loss_rpn_loc: 0.171  time: 1.7507  data_time: 0.0057  lr: 0.000015  max_mem: 5917M\n",
            "\u001b[32m[05/23 16:23:46 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:23:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:23:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:23:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.366395 (0.366395 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:23:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.314855 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:23:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:23:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:23:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.019\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\n",
            "\u001b[32m[05/23 16:23:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.515 | 1.938  | 0.007  | 0.000 | 1.050 | 0.544 |\n",
            "\u001b[32m[05/23 16:23:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.000 | C          | 0.055 | P          | 2.006 |\n",
            "| M          | 0.000 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:23:49 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:23:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:23:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:23:49 d2.evaluation.testing]: \u001b[0mcopypaste: 0.5153,1.9377,0.0071,0.0000,1.0499,0.5443\n",
            "\u001b[32m[05/23 16:24:07 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:24:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:24:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:24:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.356816 (0.356816 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:24:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.303410 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:24:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:24:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:24:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.073\n",
            "\u001b[32m[05/23 16:24:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.700 | 2.517  | 0.015  | 0.000 | 1.040 | 0.769 |\n",
            "\u001b[32m[05/23 16:24:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.000 | C          | 0.048 | P          | 2.731 |\n",
            "| M          | 0.019 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:24:09 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:24:09 d2.evaluation.testing]: \u001b[0mcopypaste: 0.6995,2.5174,0.0153,0.0000,1.0396,0.7686\n",
            "\u001b[32m[05/23 16:24:09 d2.utils.events]: \u001b[0m eta: 0:27:23  iter: 79  total_loss: 2.356  loss_cls: 1.325  loss_box_reg: 0.838  loss_rpn_cls: 0.051  loss_rpn_loc: 0.146  time: 1.7531  data_time: 0.0062  lr: 0.000020  max_mem: 5917M\n",
            "\u001b[32m[05/23 16:24:27 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:24:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:24:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:24:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.371724 (0.371724 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:24:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.323286 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:24:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:24:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:24:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074\n",
            "\u001b[32m[05/23 16:24:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.845 | 2.942  | 0.020  | 0.000 | 1.031 | 0.957 |\n",
            "\u001b[32m[05/23 16:24:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.000 | C          | 0.046 | P          | 3.307 |\n",
            "| M          | 0.026 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:24:30 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:24:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:24:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:24:30 d2.evaluation.testing]: \u001b[0mcopypaste: 0.8448,2.9420,0.0201,0.0000,1.0308,0.9573\n",
            "\u001b[32m[05/23 16:24:48 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:24:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:24:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:24:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.371268 (0.371268 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:24:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.321490 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:24:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:24:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:24:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.032\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.086\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
            "\u001b[32m[05/23 16:24:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.031 | 3.195  | 0.090  | 0.000 | 2.511 | 1.260 |\n",
            "\u001b[32m[05/23 16:24:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.025 | C          | 0.046 | P          | 3.779 |\n",
            "| M          | 0.272 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:24:50 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:24:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:24:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:24:50 d2.evaluation.testing]: \u001b[0mcopypaste: 1.0305,3.1955,0.0901,0.0000,2.5106,1.2601\n",
            "\u001b[32m[05/23 16:24:50 d2.utils.events]: \u001b[0m eta: 0:26:51  iter: 99  total_loss: 2.181  loss_cls: 1.132  loss_box_reg: 0.840  loss_rpn_cls: 0.052  loss_rpn_loc: 0.143  time: 1.7569  data_time: 0.0054  lr: 0.000025  max_mem: 5917M\n",
            "\u001b[32m[05/23 16:25:08 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:25:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:25:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:25:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.361335 (0.361335 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:25:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.311592 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:25:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:25:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:25:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.117\n",
            "\u001b[32m[05/23 16:25:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.584 | 4.842  | 0.272  | 0.000 | 4.195 | 1.733 |\n",
            "\u001b[32m[05/23 16:25:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.072 | C          | 0.082 | P          | 4.646 |\n",
            "| M          | 1.537 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:25:11 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:25:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:25:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:25:11 d2.evaluation.testing]: \u001b[0mcopypaste: 1.5840,4.8422,0.2717,0.0000,4.1949,1.7332\n",
            "\u001b[32m[05/23 16:25:28 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:25:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:25:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:25:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.366809 (0.366809 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:25:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.317359 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:25:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:25:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:25:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.136\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.142\n",
            "\u001b[32m[05/23 16:25:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.046 | 5.815  | 0.532  | 0.000 | 4.338 | 2.210 |\n",
            "\u001b[32m[05/23 16:25:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.150 | C          | 0.094 | P          | 4.957 |\n",
            "| M          | 2.981 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:25:31 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:25:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:25:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:25:31 d2.evaluation.testing]: \u001b[0mcopypaste: 2.0457,5.8148,0.5325,0.0000,4.3381,2.2095\n",
            "\u001b[32m[05/23 16:25:31 d2.utils.events]: \u001b[0m eta: 0:26:16  iter: 119  total_loss: 1.958  loss_cls: 0.963  loss_box_reg: 0.835  loss_rpn_cls: 0.041  loss_rpn_loc: 0.139  time: 1.7559  data_time: 0.0054  lr: 0.000030  max_mem: 5917M\n",
            "\u001b[32m[05/23 16:25:48 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:25:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:25:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:25:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.365171 (0.365171 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:25:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.314603 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:25:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:25:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:25:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.076\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.046\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
            "\u001b[32m[05/23 16:25:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.884 | 7.589  | 1.195  | 0.000 | 4.552 | 3.276 |\n",
            "\u001b[32m[05/23 16:25:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.321 | C          | 0.141 | P          | 6.564 |\n",
            "| M          | 4.509 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:25:51 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:25:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:25:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:25:51 d2.evaluation.testing]: \u001b[0mcopypaste: 2.8838,7.5895,1.1950,0.0000,4.5525,3.2760\n",
            "\u001b[32m[05/23 16:26:09 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:26:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:26:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:26:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.361435 (0.361435 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:26:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.311440 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:26:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:26:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:26:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.129\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
            "\u001b[32m[05/23 16:26:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.972 | 9.532  | 2.384  | 0.000 | 5.309 | 4.521 |\n",
            "\u001b[32m[05/23 16:26:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP    | category   | AP    | category   | AP    |\n",
            "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
            "| I          | 0.381 | C          | 0.259 | P          | 8.013 |\n",
            "| M          | 7.237 |            |       |            |       |\n",
            "\u001b[32m[05/23 16:26:12 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:26:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:26:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:26:12 d2.evaluation.testing]: \u001b[0mcopypaste: 3.9724,9.5324,2.3845,0.0000,5.3085,4.5209\n",
            "\u001b[32m[05/23 16:26:12 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 139  total_loss: 1.842  loss_cls: 0.853  loss_box_reg: 0.821  loss_rpn_cls: 0.032  loss_rpn_loc: 0.131  time: 1.7556  data_time: 0.0055  lr: 0.000035  max_mem: 5917M\n",
            "\u001b[32m[05/23 16:26:29 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:26:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:26:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:26:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.358019 (0.358019 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:26:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.308758 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:26:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:26:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:26:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.129\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.140\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.144\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267\n",
            "\u001b[32m[05/23 16:26:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.855 | 12.859 | 3.947  | 0.000 | 6.488 | 6.550 |\n",
            "\u001b[32m[05/23 16:26:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 0.613  | C          | 0.245 | P          | 10.979 |\n",
            "| M          | 11.585 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:26:32 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:26:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:26:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:26:32 d2.evaluation.testing]: \u001b[0mcopypaste: 5.8554,12.8586,3.9474,0.0000,6.4881,6.5496\n",
            "\u001b[32m[05/23 16:26:50 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:26:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:26:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:26:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.360375 (0.360375 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:26:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.311210 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:26:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:26:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:26:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.073\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.152\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.301\n",
            "\u001b[32m[05/23 16:26:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 7.305 | 15.905 | 5.438  | 0.000 | 8.214 | 7.730 |\n",
            "\u001b[32m[05/23 16:26:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 0.899  | C          | 0.597 | P          | 12.320 |\n",
            "| M          | 15.403 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:26:52 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:26:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:26:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:26:52 d2.evaluation.testing]: \u001b[0mcopypaste: 7.3047,15.9049,5.4382,0.0000,8.2139,7.7298\n",
            "\u001b[32m[05/23 16:26:52 d2.utils.events]: \u001b[0m eta: 0:25:06  iter: 159  total_loss: 1.772  loss_cls: 0.807  loss_box_reg: 0.805  loss_rpn_cls: 0.036  loss_rpn_loc: 0.125  time: 1.7569  data_time: 0.0050  lr: 0.000040  max_mem: 5917M\n",
            "\u001b[32m[05/23 16:27:10 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:27:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:27:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:27:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.370843 (0.370843 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:27:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.321178 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:27:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:27:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:27:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.161\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
            "\u001b[32m[05/23 16:27:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 8.911 | 19.144 | 6.774  | 0.000 | 8.878 | 9.420 |\n",
            "\u001b[32m[05/23 16:27:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 1.127  | C          | 0.418 | P          | 14.294 |\n",
            "| M          | 19.805 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:27:13 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:27:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:27:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:27:13 d2.evaluation.testing]: \u001b[0mcopypaste: 8.9108,19.1442,6.7741,0.0000,8.8784,9.4203\n",
            "\u001b[32m[05/23 16:27:31 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:27:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:27:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:27:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.362790 (0.362790 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:27:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.311692 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:27:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:27:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:27:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.231\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.117\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
            "\u001b[32m[05/23 16:27:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 10.742 | 23.136 | 7.359  | 0.000 | 8.989 | 11.652 |\n",
            "\u001b[32m[05/23 16:27:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 1.619  | C          | 0.672 | P          | 15.372 |\n",
            "| M          | 25.307 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:27:34 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:27:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:27:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:27:34 d2.evaluation.testing]: \u001b[0mcopypaste: 10.7424,23.1359,7.3587,0.0000,8.9888,11.6522\n",
            "\u001b[32m[05/23 16:27:34 d2.utils.events]: \u001b[0m eta: 0:24:30  iter: 179  total_loss: 1.712  loss_cls: 0.765  loss_box_reg: 0.808  loss_rpn_cls: 0.025  loss_rpn_loc: 0.120  time: 1.7592  data_time: 0.0052  lr: 0.000045  max_mem: 5917M\n",
            "\u001b[32m[05/23 16:27:51 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:27:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:27:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:27:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.364190 (0.364190 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:27:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.312444 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:27:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:27:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:27:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.253\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.123\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
            "\u001b[32m[05/23 16:27:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 11.472 | 25.337 | 7.468  | 0.000 | 10.776 | 12.300 |\n",
            "\u001b[32m[05/23 16:27:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 1.929  | C          | 0.592 | P          | 16.702 |\n",
            "| M          | 26.666 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:27:54 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:27:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:27:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:27:54 d2.evaluation.testing]: \u001b[0mcopypaste: 11.4724,25.3374,7.4684,0.0000,10.7763,12.3004\n",
            "\u001b[32m[05/23 16:28:12 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:28:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:28:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:28:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.351980 (0.351980 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:28:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.303527 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:28:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:28:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:28:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.204\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n",
            "\u001b[32m[05/23 16:28:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 12.836 | 27.585 | 9.012  | 0.000 | 10.737 | 13.788 |\n",
            "\u001b[32m[05/23 16:28:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 2.064  | C          | 0.612 | P          | 18.360 |\n",
            "| M          | 30.309 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:28:14 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:28:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:28:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:28:14 d2.evaluation.testing]: \u001b[0mcopypaste: 12.8364,27.5852,9.0115,0.0000,10.7367,13.7881\n",
            "\u001b[32m[05/23 16:28:14 d2.utils.events]: \u001b[0m eta: 0:23:55  iter: 199  total_loss: 1.650  loss_cls: 0.729  loss_box_reg: 0.787  loss_rpn_cls: 0.022  loss_rpn_loc: 0.112  time: 1.7586  data_time: 0.0053  lr: 0.000050  max_mem: 5917M\n",
            "\u001b[32m[05/23 16:28:32 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:28:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:28:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:28:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.365091 (0.365091 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:28:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.316185 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:28:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:28:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:28:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.123\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.199\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348\n",
            "\u001b[32m[05/23 16:28:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 13.336 | 28.793 | 9.447  | 0.000 | 12.346 | 13.930 |\n",
            "\u001b[32m[05/23 16:28:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 2.490  | C          | 0.416 | P          | 19.447 |\n",
            "| M          | 30.991 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:28:35 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:28:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:28:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:28:35 d2.evaluation.testing]: \u001b[0mcopypaste: 13.3362,28.7927,9.4466,0.0000,12.3459,13.9303\n",
            "\u001b[32m[05/23 16:28:53 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:28:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:28:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:28:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.371500 (0.371500 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:28:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.322081 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:28:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:28:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:28:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.092\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.138\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.240\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n",
            "\u001b[32m[05/23 16:28:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 13.992 | 28.184 | 9.189  | 0.000 | 13.756 | 14.703 |\n",
            "\u001b[32m[05/23 16:28:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 3.166  | C          | 0.216 | P          | 19.596 |\n",
            "| M          | 32.992 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:28:55 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:28:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:28:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:28:55 d2.evaluation.testing]: \u001b[0mcopypaste: 13.9924,28.1835,9.1894,0.0000,13.7563,14.7029\n",
            "\u001b[32m[05/23 16:28:55 d2.utils.events]: \u001b[0m eta: 0:23:19  iter: 219  total_loss: 1.612  loss_cls: 0.701  loss_box_reg: 0.791  loss_rpn_cls: 0.020  loss_rpn_loc: 0.112  time: 1.7593  data_time: 0.0054  lr: 0.000055  max_mem: 5917M\n",
            "\u001b[32m[05/23 16:29:13 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:29:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:29:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:29:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.360312 (0.360312 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:29:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.310094 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:29:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:29:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:29:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.305\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.155\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n",
            "\u001b[32m[05/23 16:29:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 14.649 | 30.530 | 9.670  | 0.000 | 14.251 | 15.504 |\n",
            "\u001b[32m[05/23 16:29:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 3.640  | C          | 1.089 | P          | 19.741 |\n",
            "| M          | 34.124 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:29:16 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:29:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:29:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:29:16 d2.evaluation.testing]: \u001b[0mcopypaste: 14.6487,30.5297,9.6699,0.0000,14.2512,15.5041\n",
            "\u001b[32m[05/23 16:29:34 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:29:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:29:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:29:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.366863 (0.366863 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:29:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.318014 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:29:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:29:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:29:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.149\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
            "\u001b[32m[05/23 16:29:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 14.323 | 31.121 | 8.549  | 0.000 | 14.973 | 14.922 |\n",
            "\u001b[32m[05/23 16:29:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 4.167  | C          | 0.319 | P          | 19.958 |\n",
            "| M          | 32.849 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:29:37 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:29:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:29:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:29:37 d2.evaluation.testing]: \u001b[0mcopypaste: 14.3231,31.1209,8.5486,0.0000,14.9732,14.9224\n",
            "\u001b[32m[05/23 16:29:37 d2.utils.events]: \u001b[0m eta: 0:22:44  iter: 239  total_loss: 1.585  loss_cls: 0.666  loss_box_reg: 0.793  loss_rpn_cls: 0.017  loss_rpn_loc: 0.110  time: 1.7608  data_time: 0.0050  lr: 0.000060  max_mem: 5918M\n",
            "\u001b[32m[05/23 16:29:54 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:29:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:29:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:29:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.371914 (0.371914 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:29:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.323073 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:29:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:29:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:29:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.224\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n",
            "\u001b[32m[05/23 16:29:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 15.841 | 34.013 | 9.851  | 0.000 | 17.137 | 16.371 |\n",
            "\u001b[32m[05/23 16:29:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 6.423  | C          | 0.354 | P          | 21.084 |\n",
            "| M          | 35.502 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:29:57 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:29:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:29:57 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:29:57 d2.evaluation.testing]: \u001b[0mcopypaste: 15.8406,34.0130,9.8513,0.0000,17.1374,16.3713\n",
            "\u001b[32m[05/23 16:30:15 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:30:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:30:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:30:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.376809 (0.376809 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:30:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.319509 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:30:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:30:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:30:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.240\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
            "\u001b[32m[05/23 16:30:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 16.678 | 35.142 | 11.528 | 0.000 | 17.933 | 17.197 |\n",
            "\u001b[32m[05/23 16:30:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 8.326  | C          | 0.252 | P          | 20.800 |\n",
            "| M          | 37.334 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:30:18 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:30:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:30:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:30:18 d2.evaluation.testing]: \u001b[0mcopypaste: 16.6781,35.1422,11.5281,0.0000,17.9330,17.1972\n",
            "\u001b[32m[05/23 16:30:18 d2.utils.events]: \u001b[0m eta: 0:22:09  iter: 259  total_loss: 1.523  loss_cls: 0.636  loss_box_reg: 0.764  loss_rpn_cls: 0.016  loss_rpn_loc: 0.103  time: 1.7615  data_time: 0.0052  lr: 0.000065  max_mem: 5918M\n",
            "\u001b[32m[05/23 16:30:35 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:30:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:30:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:30:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.355792 (0.355792 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:30:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.305994 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:30:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:30:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:30:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.128\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.020\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n",
            "\u001b[32m[05/23 16:30:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 17.523 | 37.067 | 12.765 | 0.000 | 18.599 | 18.032 |\n",
            "\u001b[32m[05/23 16:30:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 10.291 | C          | 0.108 | P          | 22.156 |\n",
            "| M          | 37.537 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:30:38 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:30:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:30:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:30:38 d2.evaluation.testing]: \u001b[0mcopypaste: 17.5228,37.0666,12.7654,0.0000,18.5994,18.0320\n",
            "\u001b[32m[05/23 16:30:56 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:30:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:30:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:30:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.370827 (0.370827 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:30:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.321598 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:30:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:30:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:30:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.385\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.385\n",
            "\u001b[32m[05/23 16:30:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 18.786 | 38.494 | 15.730 | 0.000 | 20.303 | 19.321 |\n",
            "\u001b[32m[05/23 16:30:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 12.528 | C          | 0.113 | P          | 21.617 |\n",
            "| M          | 40.886 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:30:59 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:30:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:30:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:30:59 d2.evaluation.testing]: \u001b[0mcopypaste: 18.7856,38.4936,15.7304,0.0000,20.3034,19.3206\n",
            "\u001b[32m[05/23 16:30:59 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 279  total_loss: 1.491  loss_cls: 0.611  loss_box_reg: 0.761  loss_rpn_cls: 0.019  loss_rpn_loc: 0.106  time: 1.7610  data_time: 0.0050  lr: 0.000070  max_mem: 5918M\n",
            "\u001b[32m[05/23 16:31:16 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:31:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:31:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:31:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.369462 (0.369462 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:31:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.318199 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:31:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:31:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:31:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.408\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.162\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.247\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
            "\u001b[32m[05/23 16:31:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 20.159 | 40.835 | 16.178 | 0.000 | 24.699 | 20.517 |\n",
            "\u001b[32m[05/23 16:31:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 17.084 | C          | 0.350 | P          | 21.230 |\n",
            "| M          | 41.972 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:31:19 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:31:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:31:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:31:19 d2.evaluation.testing]: \u001b[0mcopypaste: 20.1590,40.8355,16.1782,0.0000,24.6992,20.5175\n",
            "\u001b[32m[05/23 16:31:36 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:31:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:31:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:31:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.364147 (0.364147 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:31:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.310544 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:31:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:31:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:31:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.426\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
            "\u001b[32m[05/23 16:31:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 21.967 | 42.649 | 19.151 | 0.000 | 26.987 | 22.269 |\n",
            "\u001b[32m[05/23 16:31:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 20.684 | C          | 0.138 | P          | 23.542 |\n",
            "| M          | 43.503 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:31:39 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:31:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:31:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:31:39 d2.evaluation.testing]: \u001b[0mcopypaste: 21.9666,42.6489,19.1507,0.0000,26.9868,22.2691\n",
            "\u001b[32m[05/23 16:31:39 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 299  total_loss: 1.428  loss_cls: 0.572  loss_box_reg: 0.742  loss_rpn_cls: 0.012  loss_rpn_loc: 0.096  time: 1.7605  data_time: 0.0056  lr: 0.000075  max_mem: 5918M\n",
            "\u001b[32m[05/23 16:31:57 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:31:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:31:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:31:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.352626 (0.352626 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:31:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.303172 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:31:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:31:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:31:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.449\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.406\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
            "\u001b[32m[05/23 16:32:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 22.085 | 44.866 | 19.101 | 0.000 | 26.060 | 22.571 |\n",
            "\u001b[32m[05/23 16:32:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 22.908 | C          | 0.186 | P          | 23.196 |\n",
            "| M          | 42.051 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:32:00 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:32:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:32:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:32:00 d2.evaluation.testing]: \u001b[0mcopypaste: 22.0850,44.8664,19.1007,0.0000,26.0603,22.5715\n",
            "\u001b[32m[05/23 16:32:17 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:32:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:32:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:32:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.364314 (0.364314 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:32:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.313149 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:32:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:32:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:32:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.465\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.416\n",
            "\u001b[32m[05/23 16:32:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.279 | 46.490 | 22.428 | 0.000 | 29.796 | 24.833 |\n",
            "\u001b[32m[05/23 16:32:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 27.766 | C          | 0.225 | P          | 23.841 |\n",
            "| M          | 45.286 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:32:20 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:32:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:32:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:32:20 d2.evaluation.testing]: \u001b[0mcopypaste: 24.2795,46.4900,22.4278,0.0000,29.7962,24.8332\n",
            "\u001b[32m[05/23 16:32:20 d2.utils.events]: \u001b[0m eta: 0:20:21  iter: 319  total_loss: 1.396  loss_cls: 0.557  loss_box_reg: 0.740  loss_rpn_cls: 0.009  loss_rpn_loc: 0.096  time: 1.7609  data_time: 0.0050  lr: 0.000080  max_mem: 5918M\n",
            "\u001b[32m[05/23 16:32:38 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:32:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:32:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:32:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.361034 (0.361034 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:32:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.311240 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:32:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:32:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:32:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.475\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\n",
            "\u001b[32m[05/23 16:32:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.610 | 47.491 | 23.692 | 0.000 | 31.209 | 24.670 |\n",
            "\u001b[32m[05/23 16:32:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 29.563 | C          | 0.270 | P          | 23.081 |\n",
            "| M          | 45.525 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:32:40 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:32:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:32:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:32:40 d2.evaluation.testing]: \u001b[0mcopypaste: 24.6099,47.4912,23.6917,0.0000,31.2086,24.6698\n",
            "\u001b[32m[05/23 16:32:58 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:32:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:32:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:33:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.372651 (0.372651 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:33:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.321576 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:33:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:33:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:33:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
            "\u001b[32m[05/23 16:33:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 26.435 | 49.973 | 26.655 | 0.000 | 33.394 | 26.244 |\n",
            "\u001b[32m[05/23 16:33:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 32.186 | C          | 0.297 | P          | 24.354 |\n",
            "| M          | 48.902 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:33:01 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:33:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:33:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:33:01 d2.evaluation.testing]: \u001b[0mcopypaste: 26.4346,49.9733,26.6545,0.0000,33.3941,26.2441\n",
            "\u001b[32m[05/23 16:33:01 d2.utils.events]: \u001b[0m eta: 0:19:46  iter: 339  total_loss: 1.357  loss_cls: 0.531  loss_box_reg: 0.710  loss_rpn_cls: 0.008  loss_rpn_loc: 0.095  time: 1.7618  data_time: 0.0049  lr: 0.000085  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:33:19 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:33:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:33:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:33:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.366941 (0.366941 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:33:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.317562 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:33:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:33:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:33:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.516\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423\n",
            "\u001b[32m[05/23 16:33:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 26.902 | 51.631 | 26.059 | 3.366 | 34.359 | 26.517 |\n",
            "\u001b[32m[05/23 16:33:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 33.364 | C          | 0.743 | P          | 24.152 |\n",
            "| M          | 49.350 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:33:22 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:33:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:33:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:33:22 d2.evaluation.testing]: \u001b[0mcopypaste: 26.9020,51.6315,26.0589,3.3663,34.3588,26.5166\n",
            "\u001b[32m[05/23 16:33:39 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:33:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:33:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:33:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.355240 (0.355240 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:33:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.303349 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:33:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:33:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:33:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.525\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.419\n",
            "\u001b[32m[05/23 16:33:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 27.310 | 52.532 | 26.514 | 5.050 | 35.013 | 27.023 |\n",
            "\u001b[32m[05/23 16:33:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 34.960 | C          | 0.000 | P          | 25.002 |\n",
            "| M          | 49.280 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:33:42 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:33:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:33:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:33:42 d2.evaluation.testing]: \u001b[0mcopypaste: 27.3104,52.5315,26.5140,5.0495,35.0133,27.0226\n",
            "\u001b[32m[05/23 16:33:42 d2.utils.events]: \u001b[0m eta: 0:19:10  iter: 359  total_loss: 1.320  loss_cls: 0.505  loss_box_reg: 0.694  loss_rpn_cls: 0.008  loss_rpn_loc: 0.097  time: 1.7610  data_time: 0.0057  lr: 0.000090  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:34:00 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:34:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:34:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:34:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.373523 (0.373523 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:34:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.318473 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:34:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:34:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:34:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.533\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.460\n",
            "\u001b[32m[05/23 16:34:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 28.493 | 53.261 | 27.911 | 10.099 | 33.325 | 28.644 |\n",
            "\u001b[32m[05/23 16:34:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 36.145 | C          | 1.045 | P          | 24.977 |\n",
            "| M          | 51.804 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:34:02 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:34:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:34:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:34:02 d2.evaluation.testing]: \u001b[0mcopypaste: 28.4926,53.2613,27.9113,10.0990,33.3248,28.6443\n",
            "\u001b[32m[05/23 16:34:20 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:34:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:34:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:34:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.365769 (0.365769 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:34:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.306971 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:34:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:34:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:34:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.574\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.474\n",
            "\u001b[32m[05/23 16:34:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 30.113 | 57.372 | 27.096 | 5.050 | 35.134 | 30.331 |\n",
            "\u001b[32m[05/23 16:34:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 37.628 | C          | 3.839 | P          | 26.124 |\n",
            "| M          | 52.861 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:34:23 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:34:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:34:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:34:23 d2.evaluation.testing]: \u001b[0mcopypaste: 30.1128,57.3718,27.0959,5.0495,35.1339,30.3312\n",
            "\u001b[32m[05/23 16:34:23 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 379  total_loss: 1.216  loss_cls: 0.455  loss_box_reg: 0.660  loss_rpn_cls: 0.008  loss_rpn_loc: 0.094  time: 1.7611  data_time: 0.0047  lr: 0.000095  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:34:40 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:34:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:34:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:34:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.352919 (0.352919 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:34:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.302940 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:34:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:34:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:34:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.583\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479\n",
            "\u001b[32m[05/23 16:34:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 30.569 | 58.287 | 28.630 | 5.050 | 36.012 | 30.725 |\n",
            "\u001b[32m[05/23 16:34:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 38.718 | C          | 2.634 | P          | 27.328 |\n",
            "| M          | 53.596 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:34:43 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:34:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:34:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:34:43 d2.evaluation.testing]: \u001b[0mcopypaste: 30.5690,58.2865,28.6305,5.0495,36.0121,30.7253\n",
            "\u001b[32m[05/23 16:35:01 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:35:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:35:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:35:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.359344 (0.359344 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:35:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.309720 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:35:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:35:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:35:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.589\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
            "\u001b[32m[05/23 16:35:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 32.588 | 58.884 | 32.521 | 5.509 | 37.190 | 32.793 |\n",
            "\u001b[32m[05/23 16:35:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:-------|\n",
            "| I          | 40.620 | C          | 2.134 | P          | 30.699 |\n",
            "| M          | 56.900 |            |       |            |        |\n",
            "\u001b[32m[05/23 16:35:03 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:35:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:35:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:35:03 d2.evaluation.testing]: \u001b[0mcopypaste: 32.5883,58.8843,32.5212,5.5086,37.1899,32.7931\n",
            "\u001b[32m[05/23 16:35:03 d2.utils.events]: \u001b[0m eta: 0:17:58  iter: 399  total_loss: 1.151  loss_cls: 0.428  loss_box_reg: 0.626  loss_rpn_cls: 0.003  loss_rpn_loc: 0.089  time: 1.7605  data_time: 0.0054  lr: 0.000100  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:35:21 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:35:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:35:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:35:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.346463 (0.346463 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:35:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.296702 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:35:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:35:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:35:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.624\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.371\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587\n",
            "\u001b[32m[05/23 16:35:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 35.467 | 62.405 | 37.118 | 10.604 | 41.127 | 36.357 |\n",
            "\u001b[32m[05/23 16:35:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 40.625 | C          | 10.334 | P          | 32.532 |\n",
            "| M          | 58.378 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:35:24 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:35:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:35:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:35:24 d2.evaluation.testing]: \u001b[0mcopypaste: 35.4673,62.4052,37.1180,10.6040,41.1270,36.3569\n",
            "\u001b[32m[05/23 16:35:41 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:35:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:35:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:35:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.348940 (0.348940 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:35:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.299204 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:35:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:35:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:35:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.662\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.359\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.369\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.581\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.585\n",
            "\u001b[32m[05/23 16:35:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 37.168 | 66.186 | 35.870 | 10.941 | 46.096 | 36.928 |\n",
            "\u001b[32m[05/23 16:35:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 41.907 | C          | 11.172 | P          | 36.455 |\n",
            "| M          | 59.139 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:35:44 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:35:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:35:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:35:44 d2.evaluation.testing]: \u001b[0mcopypaste: 37.1683,66.1860,35.8703,10.9406,46.0957,36.9280\n",
            "\u001b[32m[05/23 16:35:44 d2.utils.events]: \u001b[0m eta: 0:17:23  iter: 419  total_loss: 1.076  loss_cls: 0.388  loss_box_reg: 0.580  loss_rpn_cls: 0.004  loss_rpn_loc: 0.090  time: 1.7599  data_time: 0.0054  lr: 0.000105  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:36:02 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:36:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:36:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:36:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.360495 (0.360495 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:36:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.310035 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:36:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:36:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:36:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.378\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.635\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.666\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.636\n",
            "\u001b[32m[05/23 16:36:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 39.532 | 69.017 | 37.752 | 15.149 | 52.592 | 39.181 |\n",
            "\u001b[32m[05/23 16:36:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 43.581 | C          | 15.738 | P          | 38.211 |\n",
            "| M          | 60.596 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:36:05 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:36:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:36:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:36:05 d2.evaluation.testing]: \u001b[0mcopypaste: 39.5317,69.0173,37.7522,15.1485,52.5922,39.1810\n",
            "\u001b[32m[05/23 16:36:22 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:36:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:36:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:36:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.356202 (0.356202 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:36:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.306488 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:36:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:36:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:36:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.706\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.378\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.621\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n",
            "\u001b[32m[05/23 16:36:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 41.056 | 70.626 | 37.791 | 16.049 | 48.985 | 41.026 |\n",
            "\u001b[32m[05/23 16:36:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 46.074 | C          | 17.986 | P          | 38.504 |\n",
            "| M          | 61.659 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:36:25 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:36:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:36:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:36:25 d2.evaluation.testing]: \u001b[0mcopypaste: 41.0558,70.6259,37.7907,16.0486,48.9854,41.0259\n",
            "\u001b[32m[05/23 16:36:25 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 439  total_loss: 0.980  loss_cls: 0.356  loss_box_reg: 0.518  loss_rpn_cls: 0.003  loss_rpn_loc: 0.095  time: 1.7600  data_time: 0.0057  lr: 0.000110  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:36:42 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:36:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:36:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:36:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.349791 (0.349791 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:36:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.299802 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:36:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:36:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:36:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.726\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.458\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642\n",
            "\u001b[32m[05/23 16:36:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 42.540 | 72.582 | 45.800 | 17.129 | 53.377 | 42.383 |\n",
            "\u001b[32m[05/23 16:36:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 48.942 | C          | 15.989 | P          | 42.868 |\n",
            "| M          | 62.361 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:36:45 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:36:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:36:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:36:45 d2.evaluation.testing]: \u001b[0mcopypaste: 42.5402,72.5817,45.7999,17.1287,53.3774,42.3826\n",
            "\u001b[32m[05/23 16:37:03 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:37:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:37:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:37:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.357809 (0.357809 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:37:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.304709 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:37:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:37:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:37:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.741\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.452\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.562\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.638\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.636\n",
            "\u001b[32m[05/23 16:37:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 43.898 | 74.086 | 45.223 | 17.624 | 56.157 | 43.612 |\n",
            "\u001b[32m[05/23 16:37:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 48.243 | C          | 16.407 | P          | 47.538 |\n",
            "| M          | 63.405 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:37:05 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:37:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:37:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:37:05 d2.evaluation.testing]: \u001b[0mcopypaste: 43.8983,74.0862,45.2234,17.6238,56.1573,43.6123\n",
            "\u001b[32m[05/23 16:37:05 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 459  total_loss: 0.870  loss_cls: 0.312  loss_box_reg: 0.463  loss_rpn_cls: 0.003  loss_rpn_loc: 0.090  time: 1.7593  data_time: 0.0046  lr: 0.000115  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:37:23 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:37:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:37:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:37:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.356190 (0.356190 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:37:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.301280 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:37:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:37:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:37:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.473\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.569\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
            "\u001b[32m[05/23 16:37:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 44.665 | 74.751 | 47.319 | 16.563 | 50.287 | 45.190 |\n",
            "\u001b[32m[05/23 16:37:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 47.997 | C          | 17.109 | P          | 51.794 |\n",
            "| M          | 61.759 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:37:26 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:37:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:37:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:37:26 d2.evaluation.testing]: \u001b[0mcopypaste: 44.6648,74.7511,47.3192,16.5629,50.2866,45.1901\n",
            "\u001b[32m[05/23 16:37:43 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:37:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:37:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:37:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.370611 (0.370611 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:37:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.320776 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:37:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:37:46 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:37:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.482\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n",
            "\u001b[32m[05/23 16:37:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 45.791 | 76.838 | 48.227 | 21.089 | 53.088 | 45.877 |\n",
            "\u001b[32m[05/23 16:37:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 50.314 | C          | 17.964 | P          | 51.585 |\n",
            "| M          | 63.301 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:37:46 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:37:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:37:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:37:46 d2.evaluation.testing]: \u001b[0mcopypaste: 45.7912,76.8379,48.2275,21.0891,53.0884,45.8771\n",
            "\u001b[32m[05/23 16:37:46 d2.utils.events]: \u001b[0m eta: 0:15:34  iter: 479  total_loss: 0.845  loss_cls: 0.294  loss_box_reg: 0.453  loss_rpn_cls: 0.003  loss_rpn_loc: 0.093  time: 1.7588  data_time: 0.0052  lr: 0.000120  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:38:04 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:38:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:38:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:38:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.375565 (0.375565 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:38:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.323824 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:38:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:38:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:38:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.782\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.489\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.226\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.679\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n",
            "\u001b[32m[05/23 16:38:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 46.169 | 78.215 | 48.894 | 22.574 | 56.999 | 45.821 |\n",
            "\u001b[32m[05/23 16:38:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 50.590 | C          | 20.000 | P          | 51.587 |\n",
            "| M          | 62.498 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:38:07 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:38:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:38:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:38:07 d2.evaluation.testing]: \u001b[0mcopypaste: 46.1687,78.2150,48.8939,22.5743,56.9994,45.8209\n",
            "\u001b[32m[05/23 16:38:24 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:38:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:38:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:38:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.357463 (0.357463 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:38:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.307194 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:38:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:38:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:38:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.795\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.560\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668\n",
            "\u001b[32m[05/23 16:38:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 47.952 | 79.473 | 50.225 | 15.149 | 56.015 | 48.160 |\n",
            "\u001b[32m[05/23 16:38:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 52.594 | C          | 24.239 | P          | 51.604 |\n",
            "| M          | 63.372 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:38:27 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: 47.9524,79.4733,50.2254,15.1485,56.0152,48.1603\n",
            "\u001b[32m[05/23 16:38:27 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 499  total_loss: 0.803  loss_cls: 0.289  loss_box_reg: 0.417  loss_rpn_cls: 0.003  loss_rpn_loc: 0.088  time: 1.7590  data_time: 0.0055  lr: 0.000125  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:38:45 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:38:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:38:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:38:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.349377 (0.349377 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:38:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.299078 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:38:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:38:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:38:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.804\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.080\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.603\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.734\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673\n",
            "\u001b[32m[05/23 16:38:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 50.145 | 80.416 | 53.912 | 30.099 | 61.605 | 49.791 |\n",
            "\u001b[32m[05/23 16:38:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 53.544 | C          | 26.190 | P          | 56.377 |\n",
            "| M          | 64.470 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:38:48 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:38:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:38:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:38:48 d2.evaluation.testing]: \u001b[0mcopypaste: 50.1453,80.4156,53.9123,30.0990,61.6045,49.7914\n",
            "\u001b[32m[05/23 16:39:05 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:39:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:39:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:39:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.358714 (0.358714 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:39:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.308475 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:39:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:39:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:39:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.799\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.555\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.601\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.674\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n",
            "\u001b[32m[05/23 16:39:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 50.132 | 79.949 | 55.497 | 50.198 | 54.110 | 50.799 |\n",
            "\u001b[32m[05/23 16:39:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 55.708 | C          | 23.476 | P          | 55.690 |\n",
            "| M          | 65.655 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:39:08 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:39:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:39:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:39:08 d2.evaluation.testing]: \u001b[0mcopypaste: 50.1321,79.9490,55.4969,50.1980,54.1102,50.7989\n",
            "\u001b[32m[05/23 16:39:08 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 519  total_loss: 0.755  loss_cls: 0.263  loss_box_reg: 0.389  loss_rpn_cls: 0.002  loss_rpn_loc: 0.087  time: 1.7592  data_time: 0.0050  lr: 0.000130  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:39:25 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:39:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:39:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:39:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.355323 (0.355323 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:39:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.304596 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:39:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:39:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:39:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.821\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.597\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.617\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.632\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
            "\u001b[32m[05/23 16:39:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 52.807 | 82.073 | 59.681 | 61.749 | 59.105 | 52.727 |\n",
            "\u001b[32m[05/23 16:39:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 59.361 | C          | 30.905 | P          | 55.919 |\n",
            "| M          | 65.044 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:39:28 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:39:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:39:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:39:28 d2.evaluation.testing]: \u001b[0mcopypaste: 52.8073,82.0735,59.6811,61.7492,59.1049,52.7267\n",
            "\u001b[32m[05/23 16:39:46 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:39:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:39:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:39:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.369972 (0.369972 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:39:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.319263 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:39:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:39:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:39:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.843\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.607\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.552\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.690\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.727\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685\n",
            "\u001b[32m[05/23 16:39:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 54.039 | 84.341 | 60.694 | 55.248 | 62.302 | 53.775 |\n",
            "\u001b[32m[05/23 16:39:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 59.543 | C          | 33.324 | P          | 58.071 |\n",
            "| M          | 65.217 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:39:48 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:39:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:39:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:39:48 d2.evaluation.testing]: \u001b[0mcopypaste: 54.0385,84.3407,60.6944,55.2475,62.3016,53.7754\n",
            "\u001b[32m[05/23 16:39:48 d2.utils.events]: \u001b[0m eta: 0:13:46  iter: 539  total_loss: 0.704  loss_cls: 0.247  loss_box_reg: 0.363  loss_rpn_cls: 0.001  loss_rpn_loc: 0.082  time: 1.7587  data_time: 0.0062  lr: 0.000135  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:40:06 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:40:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:40:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:40:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.370610 (0.370610 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:40:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.315572 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:40:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:40:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:40:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.854\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.687\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.452\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.095\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.651\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.709\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712\n",
            "\u001b[32m[05/23 16:40:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 56.436 | 85.426 | 68.714 | 45.248 | 61.204 | 56.746 |\n",
            "\u001b[32m[05/23 16:40:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 60.866 | C          | 37.789 | P          | 60.373 |\n",
            "| M          | 66.718 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:40:09 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:40:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:40:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:40:09 d2.evaluation.testing]: \u001b[0mcopypaste: 56.4363,85.4258,68.7138,45.2475,61.2045,56.7460\n",
            "\u001b[32m[05/23 16:40:26 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:40:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:40:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:40:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.354858 (0.354858 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:40:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.304450 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:40:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:40:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:40:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.871\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.535\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.654\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.707\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.704\n",
            "\u001b[32m[05/23 16:40:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 56.956 | 87.079 | 63.724 | 53.465 | 62.472 | 56.737 |\n",
            "\u001b[32m[05/23 16:40:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 61.069 | C          | 41.010 | P          | 58.458 |\n",
            "| M          | 67.285 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:40:29 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:40:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:40:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:40:29 d2.evaluation.testing]: \u001b[0mcopypaste: 56.9556,87.0789,63.7242,53.4653,62.4723,56.7369\n",
            "\u001b[32m[05/23 16:40:29 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 559  total_loss: 0.669  loss_cls: 0.238  loss_box_reg: 0.344  loss_rpn_cls: 0.001  loss_rpn_loc: 0.085  time: 1.7584  data_time: 0.0056  lr: 0.000140  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:40:46 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:40:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:40:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:40:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.357536 (0.357536 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:40:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.304979 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:40:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:40:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:40:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.555\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.835\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.645\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.665\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.717\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.701\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724\n",
            "\u001b[32m[05/23 16:40:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 55.464 | 83.513 | 64.470 | 45.050 | 54.133 | 56.792 |\n",
            "\u001b[32m[05/23 16:40:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 59.555 | C          | 31.512 | P          | 62.116 |\n",
            "| M          | 68.675 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:40:49 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:40:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:40:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:40:49 d2.evaluation.testing]: \u001b[0mcopypaste: 55.4643,83.5127,64.4700,45.0495,54.1326,56.7922\n",
            "\u001b[32m[05/23 16:41:07 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:41:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:41:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:41:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.356839 (0.356839 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:41:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.306362 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:41:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:41:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:41:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.861\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.701\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.577\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.667\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.718\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.732\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "\u001b[32m[05/23 16:41:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 57.222 | 86.096 | 70.093 | 40.198 | 64.202 | 57.738 |\n",
            "\u001b[32m[05/23 16:41:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 61.111 | C          | 40.004 | P          | 61.139 |\n",
            "| M          | 66.633 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:41:10 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:41:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:41:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:41:10 d2.evaluation.testing]: \u001b[0mcopypaste: 57.2217,86.0960,70.0926,40.1980,64.2020,57.7381\n",
            "\u001b[32m[05/23 16:41:10 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 579  total_loss: 0.645  loss_cls: 0.224  loss_box_reg: 0.336  loss_rpn_cls: 0.001  loss_rpn_loc: 0.085  time: 1.7582  data_time: 0.0055  lr: 0.000145  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:41:27 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:41:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:41:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:41:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.372777 (0.372777 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:41:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.323419 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:41:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:41:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:41:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.575\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.857\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.696\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.092\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.672\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            "\u001b[32m[05/23 16:41:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 57.462 | 85.725 | 69.579 | 40.198 | 59.211 | 58.651 |\n",
            "\u001b[32m[05/23 16:41:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 60.162 | C          | 37.993 | P          | 63.680 |\n",
            "| M          | 68.012 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:41:30 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:41:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:41:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:41:30 d2.evaluation.testing]: \u001b[0mcopypaste: 57.4618,85.7253,69.5793,40.1980,59.2108,58.6511\n",
            "\u001b[32m[05/23 16:41:47 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:41:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:41:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:41:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.372921 (0.372921 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:41:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.323407 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:41:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:41:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:41:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.882\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.756\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.597\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.672\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.717\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.721\n",
            "\u001b[32m[05/23 16:41:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 59.534 | 88.217 | 75.625 | 50.099 | 62.940 | 59.663 |\n",
            "\u001b[32m[05/23 16:41:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 62.259 | C          | 45.316 | P          | 61.984 |\n",
            "| M          | 68.577 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:41:50 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:41:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:41:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:41:50 d2.evaluation.testing]: \u001b[0mcopypaste: 59.5337,88.2174,75.6251,50.0990,62.9404,59.6634\n",
            "\u001b[32m[05/23 16:41:50 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 599  total_loss: 0.631  loss_cls: 0.224  loss_box_reg: 0.319  loss_rpn_cls: 0.000  loss_rpn_loc: 0.083  time: 1.7582  data_time: 0.0044  lr: 0.000150  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:42:08 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:42:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:42:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:42:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.376473 (0.376473 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:42:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.326264 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:42:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:42:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:42:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.608\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.893\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.769\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.695\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.708\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
            "\u001b[32m[05/23 16:42:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 60.801 | 89.306 | 76.913 | 35.149 | 61.937 | 61.775 |\n",
            "\u001b[32m[05/23 16:42:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 63.157 | C          | 49.348 | P          | 63.997 |\n",
            "| M          | 66.700 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:42:11 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:42:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:42:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:42:11 d2.evaluation.testing]: \u001b[0mcopypaste: 60.8006,89.3063,76.9134,35.1485,61.9373,61.7752\n",
            "\u001b[32m[05/23 16:42:28 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:42:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:42:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:42:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.359370 (0.359370 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:42:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.309851 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:42:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:42:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:42:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.586\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.876\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.738\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.674\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.718\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.682\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n",
            "\u001b[32m[05/23 16:42:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 58.624 | 87.600 | 73.788 | 40.198 | 53.228 | 60.183 |\n",
            "\u001b[32m[05/23 16:42:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 61.052 | C          | 40.790 | P          | 64.642 |\n",
            "| M          | 68.013 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:42:31 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:42:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:42:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:42:31 d2.evaluation.testing]: \u001b[0mcopypaste: 58.6243,87.5995,73.7883,40.1980,53.2283,60.1831\n",
            "\u001b[32m[05/23 16:42:31 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 619  total_loss: 0.606  loss_cls: 0.210  loss_box_reg: 0.305  loss_rpn_cls: 0.001  loss_rpn_loc: 0.083  time: 1.7581  data_time: 0.0056  lr: 0.000155  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:42:49 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:42:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:42:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:42:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.358885 (0.358885 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:42:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.308974 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:42:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:42:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:42:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.909\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.794\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.674\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.752\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.736\n",
            "\u001b[32m[05/23 16:42:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 62.535 | 90.864 | 79.408 | 40.198 | 67.398 | 62.859 |\n",
            "\u001b[32m[05/23 16:42:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 63.141 | C          | 52.223 | P          | 66.098 |\n",
            "| M          | 68.677 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:42:51 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:42:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:42:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:42:51 d2.evaluation.testing]: \u001b[0mcopypaste: 62.5349,90.8643,79.4084,40.1980,67.3982,62.8593\n",
            "\u001b[32m[05/23 16:43:09 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:43:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:43:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:43:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.374702 (0.374702 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:43:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.318621 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:43:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:43:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:43:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.912\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.792\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.745\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755\n",
            "\u001b[32m[05/23 16:43:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 63.248 | 91.237 | 79.166 | 50.198 | 62.142 | 64.190 |\n",
            "\u001b[32m[05/23 16:43:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 64.510 | C          | 51.838 | P          | 68.349 |\n",
            "| M          | 68.292 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:43:12 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:43:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:43:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:43:12 d2.evaluation.testing]: \u001b[0mcopypaste: 63.2476,91.2373,79.1658,50.1980,62.1419,64.1898\n",
            "\u001b[32m[05/23 16:43:12 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 639  total_loss: 0.584  loss_cls: 0.206  loss_box_reg: 0.295  loss_rpn_cls: 0.001  loss_rpn_loc: 0.082  time: 1.7579  data_time: 0.0052  lr: 0.000160  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:43:29 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:43:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:43:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:43:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.356563 (0.356563 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:43:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.306739 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:43:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:43:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:43:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.627\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.901\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.788\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.451\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.641\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.103\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.714\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.713\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.749\n",
            "\u001b[32m[05/23 16:43:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 62.664 | 90.079 | 78.804 | 45.149 | 64.062 | 63.532 |\n",
            "\u001b[32m[05/23 16:43:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 64.160 | C          | 49.374 | P          | 67.996 |\n",
            "| M          | 69.128 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:43:32 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:43:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:43:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:43:32 d2.evaluation.testing]: \u001b[0mcopypaste: 62.6643,90.0787,78.8042,45.1485,64.0623,63.5318\n",
            "\u001b[32m[05/23 16:43:50 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:43:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:43:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:43:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.371163 (0.371163 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:43:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.314189 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:43:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:43:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:43:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.901\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.772\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.103\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.722\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n",
            "\u001b[32m[05/23 16:43:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 61.982 | 90.065 | 77.214 | 70.000 | 63.998 | 62.220 |\n",
            "\u001b[32m[05/23 16:43:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 63.612 | C          | 48.983 | P          | 65.977 |\n",
            "| M          | 69.356 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:43:52 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:43:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:43:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:43:52 d2.evaluation.testing]: \u001b[0mcopypaste: 61.9820,90.0650,77.2141,70.0000,63.9977,62.2203\n",
            "\u001b[32m[05/23 16:43:52 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 659  total_loss: 0.540  loss_cls: 0.187  loss_box_reg: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.075  time: 1.7579  data_time: 0.0049  lr: 0.000165  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:44:10 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:44:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:44:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:44:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.347390 (0.347390 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:44:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.297752 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:44:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:44:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:44:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.902\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.772\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.585\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.638\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
            "\u001b[32m[05/23 16:44:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 62.443 | 90.163 | 77.193 | 50.099 | 58.505 | 63.847 |\n",
            "\u001b[32m[05/23 16:44:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 62.893 | C          | 48.777 | P          | 68.649 |\n",
            "| M          | 69.455 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:44:13 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:44:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:44:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:44:13 d2.evaluation.testing]: \u001b[0mcopypaste: 62.4434,90.1629,77.1933,50.0990,58.5055,63.8473\n",
            "\u001b[32m[05/23 16:44:30 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:44:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:44:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:44:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.355144 (0.355144 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:44:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.305351 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:44:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:44:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:44:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.916\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.824\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.665\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.101\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.721\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758\n",
            "\u001b[32m[05/23 16:44:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 64.920 | 91.580 | 82.437 | 50.099 | 66.547 | 65.852 |\n",
            "\u001b[32m[05/23 16:44:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 65.915 | C          | 55.594 | P          | 67.843 |\n",
            "| M          | 70.327 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:44:33 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:44:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:44:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:44:33 d2.evaluation.testing]: \u001b[0mcopypaste: 64.9199,91.5797,82.4373,50.0990,66.5474,65.8516\n",
            "\u001b[32m[05/23 16:44:33 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 679  total_loss: 0.548  loss_cls: 0.189  loss_box_reg: 0.281  loss_rpn_cls: 0.000  loss_rpn_loc: 0.078  time: 1.7580  data_time: 0.0053  lr: 0.000170  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:44:51 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:44:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:44:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:44:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.363903 (0.363903 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:44:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.310267 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:44:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:44:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:44:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.812\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.601\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.732\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            "\u001b[32m[05/23 16:44:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 64.890 | 92.784 | 81.214 | 60.099 | 67.614 | 65.231 |\n",
            "\u001b[32m[05/23 16:44:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 64.993 | C          | 58.518 | P          | 67.607 |\n",
            "| M          | 68.442 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:44:53 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:44:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:44:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:44:53 d2.evaluation.testing]: \u001b[0mcopypaste: 64.8899,92.7836,81.2141,60.0990,67.6142,65.2305\n",
            "\u001b[32m[05/23 16:45:11 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:45:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:45:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:45:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.374091 (0.374091 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:45:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.324124 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:45:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:45:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:45:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.915\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.766\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.551\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.736\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.699\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.745\n",
            "\u001b[32m[05/23 16:45:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 63.269 | 91.504 | 76.640 | 55.149 | 62.153 | 64.607 |\n",
            "\u001b[32m[05/23 16:45:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 63.490 | C          | 54.820 | P          | 64.476 |\n",
            "| M          | 70.291 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:45:14 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:45:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:45:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:45:14 d2.evaluation.testing]: \u001b[0mcopypaste: 63.2695,91.5040,76.6397,55.1485,62.1533,64.6068\n",
            "\u001b[32m[05/23 16:45:14 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 699  total_loss: 0.554  loss_cls: 0.184  loss_box_reg: 0.286  loss_rpn_cls: 0.000  loss_rpn_loc: 0.079  time: 1.7578  data_time: 0.0049  lr: 0.000175  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:45:31 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:45:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:45:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:45:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.371813 (0.371813 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:45:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.320594 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:45:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:45:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:45:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.638\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.925\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.800\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.661\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.696\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.722\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            "\u001b[32m[05/23 16:45:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 63.793 | 92.486 | 79.956 | 50.099 | 66.055 | 64.301 |\n",
            "\u001b[32m[05/23 16:45:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 64.069 | C          | 57.419 | P          | 64.308 |\n",
            "| M          | 69.374 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:45:34 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:45:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:45:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:45:34 d2.evaluation.testing]: \u001b[0mcopypaste: 63.7926,92.4861,79.9558,50.0990,66.0547,64.3009\n",
            "\u001b[32m[05/23 16:45:52 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:45:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:45:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:45:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.365287 (0.365287 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:45:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.306974 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:45:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:45:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:45:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.916\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.760\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.653\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
            "\u001b[32m[05/23 16:45:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 63.726 | 91.594 | 75.991 | 50.198 | 55.002 | 66.312 |\n",
            "\u001b[32m[05/23 16:45:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 65.509 | C          | 51.672 | P          | 68.153 |\n",
            "| M          | 69.570 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:45:54 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:45:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:45:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:45:54 d2.evaluation.testing]: \u001b[0mcopypaste: 63.7260,91.5943,75.9913,50.1980,55.0016,66.3122\n",
            "\u001b[32m[05/23 16:45:54 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 719  total_loss: 0.552  loss_cls: 0.182  loss_box_reg: 0.286  loss_rpn_cls: 0.000  loss_rpn_loc: 0.080  time: 1.7579  data_time: 0.0046  lr: 0.000180  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:46:12 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:46:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:46:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:46:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.367147 (0.367147 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:46:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.312239 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:46:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:46:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:46:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.935\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.809\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.651\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.655\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.105\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.708\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741\n",
            "\u001b[32m[05/23 16:46:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 64.889 | 93.482 | 80.850 | 70.000 | 65.066 | 65.537 |\n",
            "\u001b[32m[05/23 16:46:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 66.371 | C          | 56.280 | P          | 67.220 |\n",
            "| M          | 69.686 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:46:15 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:46:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:46:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:46:15 d2.evaluation.testing]: \u001b[0mcopypaste: 64.8890,93.4824,80.8502,70.0000,65.0657,65.5371\n",
            "\u001b[32m[05/23 16:46:32 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:46:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:46:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:46:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.365408 (0.365408 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:46:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.311753 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:46:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:46:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:46:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.931\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.792\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.801\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.712\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.669\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752\n",
            "\u001b[32m[05/23 16:46:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 63.947 | 93.099 | 79.213 | 80.099 | 58.698 | 65.654 |\n",
            "\u001b[32m[05/23 16:46:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 66.699 | C          | 53.721 | P          | 69.344 |\n",
            "| M          | 66.024 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:46:35 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:46:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:46:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:46:35 d2.evaluation.testing]: \u001b[0mcopypaste: 63.9468,93.0991,79.2125,80.0990,58.6983,65.6541\n",
            "\u001b[32m[05/23 16:46:35 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 739  total_loss: 0.521  loss_cls: 0.173  loss_box_reg: 0.269  loss_rpn_cls: 0.000  loss_rpn_loc: 0.076  time: 1.7577  data_time: 0.0054  lr: 0.000185  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:46:52 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:46:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:46:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:46:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.366973 (0.366973 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:46:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.317746 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:46:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:46:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:46:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.935\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.819\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.713\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.741\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.670\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755\n",
            "\u001b[32m[05/23 16:46:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 65.032 | 93.499 | 81.893 | 75.050 | 59.594 | 66.830 |\n",
            "\u001b[32m[05/23 16:46:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 65.582 | C          | 54.391 | P          | 70.063 |\n",
            "| M          | 70.095 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:46:55 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:46:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:46:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:46:55 d2.evaluation.testing]: \u001b[0mcopypaste: 65.0325,93.4989,81.8933,75.0495,59.5935,66.8297\n",
            "\u001b[32m[05/23 16:47:13 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:47:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:47:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:47:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.355587 (0.355587 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:47:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.305065 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:47:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:47:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:47:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.936\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.786\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.634\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.593\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.705\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.635\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.746\n",
            "\u001b[32m[05/23 16:47:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 63.900 | 93.597 | 78.601 | 63.366 | 59.263 | 65.837 |\n",
            "\u001b[32m[05/23 16:47:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 64.659 | C          | 57.280 | P          | 67.429 |\n",
            "| M          | 66.233 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:47:16 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:47:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:47:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:47:16 d2.evaluation.testing]: \u001b[0mcopypaste: 63.9003,93.5966,78.6008,63.3663,59.2627,65.8367\n",
            "\u001b[32m[05/23 16:47:16 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 759  total_loss: 0.508  loss_cls: 0.166  loss_box_reg: 0.260  loss_rpn_cls: 0.000  loss_rpn_loc: 0.076  time: 1.7580  data_time: 0.0057  lr: 0.000190  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:47:33 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:47:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:47:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:47:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.356351 (0.356351 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:47:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.303400 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:47:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:47:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:47:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.937\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.797\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.601\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.697\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.736\n",
            "\u001b[32m[05/23 16:47:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 63.862 | 93.724 | 79.729 | 60.099 | 62.061 | 65.035 |\n",
            "\u001b[32m[05/23 16:47:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 63.828 | C          | 55.866 | P          | 66.682 |\n",
            "| M          | 69.073 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:47:36 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:47:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:47:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:47:36 d2.evaluation.testing]: \u001b[0mcopypaste: 63.8621,93.7240,79.7294,60.0990,62.0614,65.0355\n",
            "\u001b[32m[05/23 16:47:54 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:47:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:47:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:47:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.365369 (0.365369 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:47:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.315248 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:47:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:47:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:47:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.920\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.795\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.550\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.711\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.711\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752\n",
            "\u001b[32m[05/23 16:47:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 64.464 | 91.999 | 79.537 | 55.050 | 62.760 | 65.830 |\n",
            "\u001b[32m[05/23 16:47:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 65.158 | C          | 56.676 | P          | 68.589 |\n",
            "| M          | 67.433 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:47:56 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:47:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:47:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:47:56 d2.evaluation.testing]: \u001b[0mcopypaste: 64.4637,91.9989,79.5370,55.0495,62.7602,65.8305\n",
            "\u001b[32m[05/23 16:47:56 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 779  total_loss: 0.515  loss_cls: 0.169  loss_box_reg: 0.270  loss_rpn_cls: 0.000  loss_rpn_loc: 0.077  time: 1.7583  data_time: 0.0054  lr: 0.000195  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:48:14 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:48:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:48:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:48:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.363950 (0.363950 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:48:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.313657 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.940\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.801\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.901\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.636\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.746\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.900\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.686\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756\n",
            "\u001b[32m[05/23 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 65.584 | 94.004 | 80.087 | 90.099 | 63.565 | 66.578 |\n",
            "\u001b[32m[05/23 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 65.029 | C          | 58.946 | P          | 68.199 |\n",
            "| M          | 70.160 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:48:17 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:48:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:48:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:48:17 d2.evaluation.testing]: \u001b[0mcopypaste: 65.5837,94.0040,80.0869,90.0990,63.5654,66.5780\n",
            "\u001b[32m[05/23 16:48:34 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:48:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:48:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:48:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.379169 (0.379169 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:48:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.321973 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:48:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:48:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:48:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.950\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.823\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.671\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.116\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.712\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.738\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.707\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
            "\u001b[32m[05/23 16:48:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 66.483 | 95.036 | 82.265 | 75.050 | 67.050 | 67.353 |\n",
            "\u001b[32m[05/23 16:48:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 66.467 | C          | 63.766 | P          | 65.283 |\n",
            "| M          | 70.417 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:48:37 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:48:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:48:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:48:37 d2.evaluation.testing]: \u001b[0mcopypaste: 66.4832,95.0363,82.2650,75.0495,67.0502,67.3528\n",
            "\u001b[32m[05/23 16:48:37 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 799  total_loss: 0.486  loss_cls: 0.157  loss_box_reg: 0.254  loss_rpn_cls: 0.000  loss_rpn_loc: 0.074  time: 1.7581  data_time: 0.0046  lr: 0.000200  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:48:55 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:48:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:48:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:48:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.370073 (0.370073 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:48:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.318936 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:48:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:48:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:48:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.942\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.865\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.701\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.652\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.705\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759\n",
            "\u001b[32m[05/23 16:48:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 67.196 | 94.239 | 86.469 | 70.099 | 65.243 | 68.673 |\n",
            "\u001b[32m[05/23 16:48:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 67.781 | C          | 61.723 | P          | 69.901 |\n",
            "| M          | 69.378 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:48:57 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:48:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:48:57 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:48:57 d2.evaluation.testing]: \u001b[0mcopypaste: 67.1959,94.2394,86.4693,70.0990,65.2434,68.6733\n",
            "\u001b[32m[05/23 16:49:15 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:49:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:49:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:49:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.376383 (0.376383 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:49:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.325646 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:49:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:49:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:49:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.933\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.765\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.701\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.598\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.712\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.736\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.651\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752\n",
            "\u001b[32m[05/23 16:49:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 64.328 | 93.295 | 76.531 | 70.099 | 59.809 | 66.138 |\n",
            "\u001b[32m[05/23 16:49:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 64.726 | C          | 57.965 | P          | 69.975 |\n",
            "| M          | 64.644 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:49:17 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:49:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:49:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:49:17 d2.evaluation.testing]: \u001b[0mcopypaste: 64.3277,93.2953,76.5306,70.0990,59.8086,66.1384\n",
            "\u001b[32m[05/23 16:49:17 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 819  total_loss: 0.486  loss_cls: 0.160  loss_box_reg: 0.252  loss_rpn_cls: 0.000  loss_rpn_loc: 0.072  time: 1.7581  data_time: 0.0052  lr: 0.000205  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:49:35 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:49:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:49:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:49:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.352875 (0.352875 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:49:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.302028 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:49:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:49:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:49:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.960\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.838\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.744\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.708\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.751\n",
            "\u001b[32m[05/23 16:49:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 67.499 | 96.037 | 83.840 | 75.050 | 66.033 | 68.443 |\n",
            "\u001b[32m[05/23 16:49:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 64.543 | C          | 65.572 | P          | 69.401 |\n",
            "| M          | 70.481 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:49:38 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:49:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:49:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:49:38 d2.evaluation.testing]: \u001b[0mcopypaste: 67.4992,96.0373,83.8402,75.0495,66.0330,68.4434\n",
            "\u001b[32m[05/23 16:49:55 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:49:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:49:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:49:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.360225 (0.360225 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:49:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.309161 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:49:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:49:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:49:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.959\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.871\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.645\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.713\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.744\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.695\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            "\u001b[32m[05/23 16:49:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 68.297 | 95.922 | 87.128 | 80.000 | 64.529 | 69.563 |\n",
            "\u001b[32m[05/23 16:49:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.157 | C          | 68.134 | P          | 67.861 |\n",
            "| M          | 69.037 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:49:58 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:49:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:49:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:49:58 d2.evaluation.testing]: \u001b[0mcopypaste: 68.2972,95.9218,87.1278,80.0000,64.5285,69.5634\n",
            "\u001b[32m[05/23 16:49:58 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 839  total_loss: 0.504  loss_cls: 0.165  loss_box_reg: 0.265  loss_rpn_cls: 0.000  loss_rpn_loc: 0.073  time: 1.7582  data_time: 0.0059  lr: 0.000210  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:50:16 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:50:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:50:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:50:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.359608 (0.359608 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:50:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.308751 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:50:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:50:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:50:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.678\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.960\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.849\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.680\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.713\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.745\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.744\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.745\n",
            "\u001b[32m[05/23 16:50:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 67.771 | 96.018 | 84.924 | 75.050 | 67.960 | 68.165 |\n",
            "\u001b[32m[05/23 16:50:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 65.032 | C          | 67.149 | P          | 67.609 |\n",
            "| M          | 71.292 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:50:18 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:50:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:50:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:50:18 d2.evaluation.testing]: \u001b[0mcopypaste: 67.7705,96.0177,84.9240,75.0495,67.9602,68.1653\n",
            "\u001b[32m[05/23 16:50:36 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:50:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:50:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:50:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.355840 (0.355840 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:50:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.306101 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:50:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:50:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:50:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.940\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.788\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.725\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.722\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.668\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.766\n",
            "\u001b[32m[05/23 16:50:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 66.214 | 93.977 | 78.849 | 72.525 | 61.054 | 67.951 |\n",
            "\u001b[32m[05/23 16:50:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 66.712 | C          | 59.937 | P          | 68.826 |\n",
            "| M          | 69.383 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:50:39 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:50:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:50:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:50:39 d2.evaluation.testing]: \u001b[0mcopypaste: 66.2143,93.9775,78.8487,72.5248,61.0539,67.9508\n",
            "\u001b[32m[05/23 16:50:39 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 859  total_loss: 0.457  loss_cls: 0.148  loss_box_reg: 0.245  loss_rpn_cls: 0.000  loss_rpn_loc: 0.071  time: 1.7580  data_time: 0.0060  lr: 0.000215  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:50:56 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:50:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:50:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:50:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.353002 (0.353002 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:50:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.302955 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:50:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:50:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:50:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.958\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.845\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.651\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.720\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.753\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.723\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759\n",
            "\u001b[32m[05/23 16:50:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 68.112 | 95.771 | 84.471 | 80.000 | 65.078 | 69.272 |\n",
            "\u001b[32m[05/23 16:50:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.593 | C          | 63.661 | P          | 70.269 |\n",
            "| M          | 69.927 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:50:59 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:50:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:50:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:50:59 d2.evaluation.testing]: \u001b[0mcopypaste: 68.1125,95.7713,84.4710,80.0000,65.0779,69.2721\n",
            "\u001b[32m[05/23 16:51:17 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:51:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:51:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:51:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.358080 (0.358080 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:51:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.302783 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:51:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:51:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:51:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.700\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.964\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.870\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.701\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.763\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765\n",
            "\u001b[32m[05/23 16:51:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 69.996 | 96.393 | 86.953 | 80.000 | 70.082 | 70.306 |\n",
            "\u001b[32m[05/23 16:51:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.813 | C          | 68.887 | P          | 72.195 |\n",
            "| M          | 70.089 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:51:20 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:51:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:51:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:51:20 d2.evaluation.testing]: \u001b[0mcopypaste: 69.9962,96.3930,86.9526,80.0000,70.0816,70.3057\n",
            "\u001b[32m[05/23 16:51:20 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 879  total_loss: 0.466  loss_cls: 0.145  loss_box_reg: 0.241  loss_rpn_cls: 0.000  loss_rpn_loc: 0.070  time: 1.7580  data_time: 0.0059  lr: 0.000220  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:51:37 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:51:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:51:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:51:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.375741 (0.375741 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:51:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.325240 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:51:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:51:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:51:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.695\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.961\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.763\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771\n",
            "\u001b[32m[05/23 16:51:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 69.487 | 96.124 | 84.987 | 80.000 | 66.429 | 70.612 |\n",
            "\u001b[32m[05/23 16:51:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.639 | C          | 66.566 | P          | 70.874 |\n",
            "| M          | 71.868 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:51:40 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:51:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:51:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:51:40 d2.evaluation.testing]: \u001b[0mcopypaste: 69.4867,96.1239,84.9867,80.0000,66.4287,70.6121\n",
            "\u001b[32m[05/23 16:51:58 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:51:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:51:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:52:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.349074 (0.349074 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:52:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.299321 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:52:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:52:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:52:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.964\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.852\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.801\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.704\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.116\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.752\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.701\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761\n",
            "\u001b[32m[05/23 16:52:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 69.120 | 96.365 | 85.181 | 80.099 | 65.968 | 70.380 |\n",
            "\u001b[32m[05/23 16:52:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.207 | C          | 66.905 | P          | 71.697 |\n",
            "| M          | 69.672 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:52:01 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:52:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:52:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:52:01 d2.evaluation.testing]: \u001b[0mcopypaste: 69.1203,96.3649,85.1806,80.0990,65.9684,70.3797\n",
            "\u001b[32m[05/23 16:52:01 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 899  total_loss: 0.457  loss_cls: 0.139  loss_box_reg: 0.249  loss_rpn_cls: 0.000  loss_rpn_loc: 0.066  time: 1.7584  data_time: 0.0054  lr: 0.000225  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:52:18 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:52:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:52:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:52:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.376915 (0.376915 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:52:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.325712 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:52:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:52:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:52:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.690\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.960\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.870\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.801\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.672\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.728\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.760\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.709\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.769\n",
            "\u001b[32m[05/23 16:52:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 69.039 | 95.951 | 87.046 | 80.099 | 67.216 | 70.307 |\n",
            "\u001b[32m[05/23 16:52:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 65.457 | C          | 68.389 | P          | 71.764 |\n",
            "| M          | 70.543 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:52:21 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:52:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:52:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:52:21 d2.evaluation.testing]: \u001b[0mcopypaste: 69.0385,95.9513,87.0460,80.0990,67.2157,70.3074\n",
            "\u001b[32m[05/23 16:52:39 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:52:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:52:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:52:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.358925 (0.358925 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:52:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.301033 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:52:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:52:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:52:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.693\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.967\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.842\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.731\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.759\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768\n",
            "\u001b[32m[05/23 16:52:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 69.290 | 96.723 | 84.157 | 85.050 | 66.439 | 70.226 |\n",
            "\u001b[32m[05/23 16:52:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.507 | C          | 67.396 | P          | 71.395 |\n",
            "| M          | 69.861 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:52:42 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:52:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:52:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:52:42 d2.evaluation.testing]: \u001b[0mcopypaste: 69.2898,96.7227,84.1573,85.0495,66.4395,70.2261\n",
            "\u001b[32m[05/23 16:52:42 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 919  total_loss: 0.448  loss_cls: 0.138  loss_box_reg: 0.227  loss_rpn_cls: 0.000  loss_rpn_loc: 0.069  time: 1.7587  data_time: 0.0065  lr: 0.000230  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:52:59 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:52:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:52:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:53:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.364401 (0.364401 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:53:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.312212 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:53:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:53:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:53:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.958\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.670\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.759\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.731\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
            "\u001b[32m[05/23 16:53:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 68.131 | 95.794 | 84.987 | 85.050 | 66.962 | 68.792 |\n",
            "\u001b[32m[05/23 16:53:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 67.885 | C          | 62.609 | P          | 71.547 |\n",
            "| M          | 70.485 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:53:02 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:53:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:53:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:53:02 d2.evaluation.testing]: \u001b[0mcopypaste: 68.1314,95.7945,84.9873,85.0495,66.9618,68.7917\n",
            "\u001b[32m[05/23 16:53:19 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:53:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:53:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:53:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.362369 (0.362369 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:53:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.310195 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:53:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:53:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:53:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.963\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.859\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.672\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.738\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759\n",
            "\u001b[32m[05/23 16:53:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 68.681 | 96.337 | 85.905 | 80.000 | 67.220 | 69.440 |\n",
            "\u001b[32m[05/23 16:53:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.487 | C          | 65.797 | P          | 69.221 |\n",
            "| M          | 71.219 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:53:22 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:53:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:53:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:53:22 d2.evaluation.testing]: \u001b[0mcopypaste: 68.6810,96.3375,85.9052,80.0000,67.2202,69.4396\n",
            "\u001b[32m[05/23 16:53:22 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 939  total_loss: 0.431  loss_cls: 0.131  loss_box_reg: 0.235  loss_rpn_cls: 0.000  loss_rpn_loc: 0.070  time: 1.7586  data_time: 0.0053  lr: 0.000235  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:53:40 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:53:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:53:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:53:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.371439 (0.371439 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:53:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.320516 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:53:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:53:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:53:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.705\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.969\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.853\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.683\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.738\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.730\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772\n",
            "\u001b[32m[05/23 16:53:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 70.549 | 96.943 | 85.340 | 75.050 | 68.255 | 71.426 |\n",
            "\u001b[32m[05/23 16:53:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.845 | C          | 68.719 | P          | 72.959 |\n",
            "| M          | 71.672 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:53:43 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:53:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:53:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:53:43 d2.evaluation.testing]: \u001b[0mcopypaste: 70.5489,96.9433,85.3403,75.0495,68.2548,71.4260\n",
            "\u001b[32m[05/23 16:54:00 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:54:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:54:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:54:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.365992 (0.365992 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:54:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.315859 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:54:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:54:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:54:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.693\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.969\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.843\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.679\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.758\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.720\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
            "\u001b[32m[05/23 16:54:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 69.283 | 96.876 | 84.347 | 85.050 | 67.856 | 70.162 |\n",
            "\u001b[32m[05/23 16:54:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 66.500 | C          | 68.429 | P          | 71.334 |\n",
            "| M          | 70.868 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:54:03 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:54:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:54:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:54:03 d2.evaluation.testing]: \u001b[0mcopypaste: 69.2829,96.8765,84.3467,85.0495,67.8558,70.1623\n",
            "\u001b[32m[05/23 16:54:03 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 959  total_loss: 0.440  loss_cls: 0.132  loss_box_reg: 0.237  loss_rpn_cls: 0.000  loss_rpn_loc: 0.066  time: 1.7588  data_time: 0.0058  lr: 0.000240  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:54:21 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:54:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:54:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:54:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.353854 (0.353854 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:54:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.303014 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:54:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:54:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:54:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.694\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.870\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.703\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.727\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.755\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.757\n",
            "\u001b[32m[05/23 16:54:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 69.378 | 97.700 | 87.024 | 75.050 | 70.263 | 69.778 |\n",
            "\u001b[32m[05/23 16:54:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 66.949 | C          | 68.445 | P          | 72.040 |\n",
            "| M          | 70.078 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:54:23 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:54:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:54:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:54:23 d2.evaluation.testing]: \u001b[0mcopypaste: 69.3777,97.7000,87.0241,75.0495,70.2631,69.7781\n",
            "\u001b[32m[05/23 16:54:41 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:54:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:54:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:54:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.372890 (0.372890 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:54:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.321926 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:54:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:54:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:54:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.951\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.844\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.670\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.722\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.740\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752\n",
            "\u001b[32m[05/23 16:54:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 67.403 | 95.138 | 84.397 | 75.050 | 67.029 | 67.971 |\n",
            "\u001b[32m[05/23 16:54:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 66.935 | C          | 61.709 | P          | 69.858 |\n",
            "| M          | 71.111 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:54:44 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:54:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:54:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:54:44 d2.evaluation.testing]: \u001b[0mcopypaste: 67.4034,95.1376,84.3972,75.0495,67.0288,67.9710\n",
            "\u001b[32m[05/23 16:54:44 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 979  total_loss: 0.436  loss_cls: 0.136  loss_box_reg: 0.231  loss_rpn_cls: 0.000  loss_rpn_loc: 0.065  time: 1.7586  data_time: 0.0054  lr: 0.000245  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:55:02 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:55:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:55:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:55:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.360525 (0.360525 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:55:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.309322 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:55:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:55:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:55:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.694\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.969\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.869\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.692\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.730\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.759\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.763\n",
            "\u001b[32m[05/23 16:55:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 69.423 | 96.880 | 86.878 | 85.050 | 69.202 | 70.098 |\n",
            "\u001b[32m[05/23 16:55:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.862 | C          | 67.863 | P          | 70.253 |\n",
            "| M          | 70.712 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:55:04 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:55:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:55:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:55:04 d2.evaluation.testing]: \u001b[0mcopypaste: 69.4227,96.8799,86.8780,85.0495,69.2019,70.0981\n",
            "\u001b[32m[05/23 16:55:25 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 16:55:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 16:55:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 16:55:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.379276 (0.379276 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:55:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.323760 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 16:55:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 16:55:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to custom_eval/coco_instances_results.json\n",
            "\u001b[32m[05/23 16:55:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.689\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.967\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.869\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.697\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.728\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.757\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755\n",
            "\u001b[32m[05/23 16:55:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 68.855 | 96.671 | 86.902 | 85.050 | 69.652 | 68.895 |\n",
            "\u001b[32m[05/23 16:55:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.137 | C          | 68.232 | P          | 70.205 |\n",
            "| M          | 68.847 |            |        |            |        |\n",
            "\u001b[32m[05/23 16:55:28 d2.engine.defaults]: \u001b[0mEvaluation results for data_test in csv format:\n",
            "\u001b[32m[05/23 16:55:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/23 16:55:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/23 16:55:28 d2.evaluation.testing]: \u001b[0mcopypaste: 68.8553,96.6708,86.9021,85.0495,69.6523,68.8948\n",
            "\u001b[32m[05/23 16:55:28 d2.utils.events]: \u001b[0m eta: 0:00:01  iter: 999  total_loss: 0.406  loss_cls: 0.126  loss_box_reg: 0.220  loss_rpn_cls: 0.000  loss_rpn_loc: 0.065  time: 1.7589  data_time: 0.0057  lr: 0.000250  max_mem: 5919M\n",
            "\u001b[32m[05/23 16:55:28 d2.engine.hooks]: \u001b[0mOverall training speed: 997 iterations in 0:29:15 (1.7607 s / it)\n",
            "\u001b[32m[05/23 16:55:28 d2.engine.hooks]: \u001b[0mTotal training time: 0:33:57 (0:04:41 on hooks)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBXeH8UXFcqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF",
        "colab_type": "text"
      },
      "source": [
        "## Inference & evaluation using the trained model\n",
        "Now, let's run inference with the trained model on the balloon validation dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"data_test\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO",
        "colab_type": "text"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LhISJqWXgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!dir\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = make_data_dicts(\"data/jsons_comparacion_de_redes/jsons_dientes_enumerados/test\", \"data/images\")\n",
        "for d in random.sample(dataset_dicts, 6):   \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata = dataset_metadata, \n",
        "                   scale = 0.5, \n",
        "                   #instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kblA1IyFvWbT",
        "colab_type": "text"
      },
      "source": [
        "We can also evaluate its performance using AP metric implemented in COCO API.\n",
        "This gives an AP of ~70%. Not bad!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9tECBQCvMv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "outputId": "8ca3668e-f671-4964-a360-fa49a384d7fb"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"data_test\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"data_test\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "# another equivalent way is to use trainer.test"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[05/23 17:05:58 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/23 17:05:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
            "\u001b[32m[05/23 17:05:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 images\n",
            "\u001b[32m[05/23 17:06:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.354398 (0.354398 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 17:06:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.297983 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/23 17:06:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/23 17:06:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
            "\u001b[32m[05/23 17:06:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.689\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.967\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.869\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.697\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.728\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.850\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.757\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755\n",
            "\u001b[32m[05/23 17:06:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 68.855 | 96.671 | 86.902 | 85.050 | 69.652 | 68.895 |\n",
            "\u001b[32m[05/23 17:06:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| I          | 68.137 | C          | 68.232 | P          | 70.205 |\n",
            "| M          | 68.847 |            |        |            |        |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 68.85525085140134,\n",
              "               'AP-C': 68.23238990565723,\n",
              "               'AP-I': 68.13691075013793,\n",
              "               'AP-M': 68.84698164263861,\n",
              "               'AP-P': 70.20472110717161,\n",
              "               'AP50': 96.67084993706713,\n",
              "               'AP75': 86.90205875285112,\n",
              "               'APl': 68.89478178553917,\n",
              "               'APm': 69.65234559170203,\n",
              "               'APs': 85.04950495049505})])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIBDAUPehmlv",
        "colab_type": "text"
      },
      "source": [
        "## Copy all results in drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rtge0G2hl06",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4dec8a4-dcad-4d45-a9cb-de2e2194dbd6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount = True)\n",
        "#%mkdir \"/gdrive/My Drive/models/faster_rcnn\" #o el directorio que se quiera\n",
        "%cp -r \"output/.\" \"/gdrive/My Drive/models/faster_rcnn\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsdUcbGi3dcX",
        "colab_type": "text"
      },
      "source": [
        "#Predicting an image and making a .json with it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWd5_1zmsFca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import base64\n",
        "\n",
        "#function to make a .json out of a single image\n",
        "def predict_img_and_make_json(img_path, predictor):\n",
        "  #img file name without dirname\n",
        "  img_name = os.path.basename(img_path)\n",
        "  #make base64 of image (its a field in the .json)\n",
        "  encoded = base64.b64encode(open(img_path, \"rb\").read())\n",
        "  #predict\n",
        "  img = cv2.imread(img_path)\n",
        "  outputs = predictor(img)\n",
        "  #make the .json out of the prediction\n",
        "  inst = outputs['instances']\n",
        "  height, width = inst.image_size\n",
        "  inst_fields = inst.get_fields()\n",
        "  #boxes found\n",
        "  pred_boxes = inst_fields['pred_boxes']\n",
        "  #classes found (same length as pred_boxes)\n",
        "  pred_classes = inst_fields['pred_classes']\n",
        "  #list containing all the boxes that were found\n",
        "  shapes_list = []\n",
        "  for i in range(len(pred_boxes)):\n",
        "    box = pred_boxes[i].tensor[0].cpu().numpy()\n",
        "    xmin, ymin, xmax, ymax = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
        "    #the label that will be stored in the .json is the numeric label corresponding\n",
        "    #to the \"category_id\" assigned in the dataset. It could be possible to use\n",
        "    #the metadata of the dataset to get the class name corresponding to the category_id\n",
        "    label = int( pred_classes[i].cpu().numpy() )\n",
        "    #dictionary for the box being processed\n",
        "    shape_dict = {\"line_color\":None, \"fill_color\":None, \"label\":str(label),\n",
        "                  \"points\":[[xmin,ymin],[xmax,ymax]], \"group_id\":None, \"shape_type\":\"rectangle\",\"flags\": {}}\n",
        "    shapes_list.append(shape_dict)\n",
        "  \n",
        "  #make the .json\n",
        "  output_dict = {\n",
        "    \"version\": \"4.2.9\",\n",
        "    \"flags\": {},\n",
        "    \"shapes\": shapes_list,\n",
        "    \"imagePath\":img_name,\n",
        "    \"imageData\": str(encoded)[1::],\n",
        "    \"imageHeight\": height,\n",
        "    \"imageWidth\": width,\n",
        "    \"lineColor\": [\n",
        "      0,\n",
        "      255,\n",
        "      0,\n",
        "      128\n",
        "    ],\n",
        "    \"fillColor\": [\n",
        "      255,\n",
        "      0,\n",
        "      0,\n",
        "      128\n",
        "    ]\n",
        "  }\n",
        "\n",
        "  #write the .json\n",
        "  output_json_file_name = img_path.split('.')[0] + '.json'\n",
        "  with open(output_json_file_name, 'w') as outfile:\n",
        "    json.dump(output_dict, outfile, indent=4)\n",
        "\n",
        "#function to predict and make .jsons of all the images in a folder\n",
        "def predict_folder_and_make_jsons(folder_path, predictor):\n",
        "  imgs_list = os.listdir(folder_path)\n",
        "  for img_file in imgs_list:\n",
        "    img_path = os.path.join(folder_path, img_file)\n",
        "    try:\n",
        "      predict_img_and_make_json(img_path, predictor)\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "predict_folder_and_make_jsons('data/images_05_04', predictor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDp8bHjy6MK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!zip -r /content/file.zip /content/X-ray-object-detection/data/images_05_04"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}